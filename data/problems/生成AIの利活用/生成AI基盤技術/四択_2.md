## 問題
### 生成AI基盤技術
生成AIの性能評価指標として最も適切な組み合わせは何ですか？

## 選択肢
A. Perplexityのみを使用した単一指標評価

B. 人間評価のみに依存した主観的評価

C. BLEU、ROUGE、BERTScore、人間評価を組み合わせた多面的評価

D. 処理速度とメモリ使用量のみを重視した効率性評価

## 解答
C

## 解説
生成AIの性能評価では、「BLEU、ROUGE、BERTScore、人間評価を組み合わせた多面的評価」が最も適切なため、選択肢Cが正解です。

**多面的評価の必要性：**

単一指標では生成AIの複雑な能力を適切に評価できず、異なる指標が異なる側面（流暢性、正確性、創造性等）を測定し、実用性と技術的性能の両方を考慮する必要があります。

**2024-2025年の評価指標進化：**

- **LLM-as-a-Judge**：GPT-4等を評価者として活用する手法の普及
- **Zero-shot Benchmarking**：事前学習なしでの評価能力測定
- **Faithfulness評価**：生成内容の事実正確性を重視
- **Toxicity/Harmfulness評価**：安全性と倫理性の評価強化
- **SelfCheckGPT**：外部知識なしでハルシネーション検出
- **FActScore**：原子的事実の正確性評価手法

**各評価指標の役割：**

- **BLEU/ROUGE**：参照文との類似度、基本的な品質指標
- **BERTScore**：意味的類似度、文脈理解の評価
- **人間評価**：実用性、満足度、創造性の評価
- **新興指標**：Distinct-N（多様性）、SELF-BLEU（一貫性）

**最新研究の知見：**

TruthfulQA研究（事実正確性評価の標準化）、HaluEval研究（包括的ハルシネーション評価フレームワーク）、MT評価研究（生成ベース評価がスコアベース評価より優秀）、Constitutional AI研究（自己修正による品質向上）が重要な進展を示しています。

**実践的な評価フレームワーク：**

自動評価（効率性と一貫性を提供）、人間評価（実用性と満足度を測定）、ハイブリッド評価（両者の利点を組み合わせ）、継続的評価（運用中の性能監視）が必要です。

**他の選択肢が不適切な理由：**

- **A**：Perplexityは言語モデルの基本性能のみ、実用性は測定不可能です。

- **B**：人間評価のみでは主観性とコストの問題があります。

- **D**：効率性は重要ですが、出力品質を無視すると実用性が低下します。

現代の生成AI評価では、技術的指標と人間中心の評価を統合した包括的アプローチが標準となっています。 