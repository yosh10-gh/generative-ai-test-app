## 問題
### 生成AIリスク管理
生成AIが社会に与える最も深刻なリスクとして、2024年の研究で特に懸念されている「誤情報の拡散」と「社会的信頼の失墜」に対する効果的な対策の組み合わせはどれか。

## 選択肢
A. 技術的性能の向上のみに集中する

B. ファクトチェック機能の強化、出典明示の義務化、リテラシー教育の推進

C. 利用料金の値上げによる利用者数の制限のみ

D. 開発企業による自主規制のみに依存する

## 解答
B

## 解説
2024年の研究では、生成AIによる誤情報拡散と社会的信頼の失墜が深刻な社会問題として認識されており、技術的・制度的・教育的な多層的アプローチが必要なため、選択肢Bが正解です。

**効果的な対策の組み合わせ：**

- **ファクトチェック機能の強化**：リアルタイムでの情報検証システムの導入、複数の信頼できる情報源との照合機能、不確実な情報に対する警告表示の自動化、2024年の技術進歩によりSelfCheckGPTやFActScoreなどの検証技術が実用化

- **出典明示の義務化**：生成された情報の根拠となるデータソースの明示、学習データの透明性確保と品質管理、情報の信頼性レベルの可視化、トレーサビリティの確保による責任の所在の明確化

- **リテラシー教育の推進**：一般市民のAIリテラシー向上プログラム、生成AIの限界と適切な利用方法の教育、批判的思考力の育成と情報の真偽判断能力の向上、教育機関・企業・政府が連携した包括的な教育体制の構築

**誤情報拡散の深刻性：**

2024年の事例として、ベルギーでAIチャットボットとの対話後に自殺した男性の事件、日本でも生成AIを悪用したコンピューターウイルス作成事件が発生（全国初の摘発）、ディープフェイク技術の進化により偽情報の精度と拡散力が急激に向上しています。

**他の選択肢が不適切な理由：**

- **A**：技術改善は重要だが、社会的対策が欠如しています。

- **C**：アクセス制限は根本的解決にならず、デジタルデバイドを拡大します。

- **D**：自主規制のみでは限界があり、外部チェック機能が必要です。 