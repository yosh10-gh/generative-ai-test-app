# 四択問題1：生成AIの技術的リスクと対策

## 問題
生成AIシステムにおける技術的リスクの中で、最も深刻な影響を与える可能性が高く、2024年の最新研究で重点的に対策が検討されているリスクの組み合わせはどれか。

A) データ品質の低下とモデルの過学習のみ
B) ハルシネーション（幻覚）、バイアス、プロンプトインジェクション攻撃
C) 計算コストの増大と学習時間の延長のみ
D) ユーザーインターフェースの複雑化と操作性の問題のみ

## 正解
B) ハルシネーション（幻覚）、バイアス、プロンプトインジェクション攻撃

## 解説
生成AIシステムにおける技術的リスクは多岐にわたりますが、2024年の最新研究では以下の3つのリスクが最も深刻で包括的な対策が必要とされています。

**ハルシネーション（幻覚）**
- 事実に基づかない情報を生成する現象
- 2024年の研究では、SelfCheckGPT、FActScore、TruthfulQAなどの検出技術が進化
- 医療、法務、金融分野では致命的な影響を与える可能性

**バイアス**
- 学習データの偏りによる差別的な出力
- 2024年のOpenEthics研究では、29のオープンソースLLMで包括的な倫理評価を実施
- 性別、人種、年齢、地域などの属性に対する不公平な判断のリスク

**プロンプトインジェクション攻撃**
- 悪意のある指示によってAIの動作を意図的に操作する攻撃
- 2024年の日本AI Safety Instituteの報告では、敵対的プロンプトへの対策が重要課題として位置づけ
- システムの制御を奪われ、機密情報の漏洩や不正な操作のリスク

これらのリスクは相互に関連し合い、単独での対策では不十分であることが2024年の研究で明らかになっています。包括的なリスク管理フレームワークの構築が急務とされています。

**選択肢の解説**
- A) 技術的な問題ではあるが、社会的影響は限定的
- C) 運用上の課題であり、安全性に直接関わるリスクではない
- D) ユーザビリティの問題であり、倫理的・安全性リスクとは異なる 