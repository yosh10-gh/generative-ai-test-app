## 問題
### 生成AIリスク管理
生成AIシステムにおける技術的リスクの中で、最も深刻な影響を与える可能性が高く、2024年の最新研究で重点的に対策が検討されているリスクの組み合わせはどれか。

## 選択肢
A. データ品質の低下とモデルの過学習のみ

B. ハルシネーション（幻覚）、バイアス、プロンプトインジェクション攻撃

C. 計算コストの増大と学習時間の延長のみ

D. ユーザーインターフェースの複雑化と操作性の問題のみ

## 解答
B

## 解説
生成AIシステムにおける技術的リスクは多岐にわたりますが、2024年の最新研究では選択肢Bの3つのリスクが最も深刻で包括的な対策が必要とされています。

**最重要技術的リスクの組み合わせ：**

- **ハルシネーション（幻覚）**：事実に基づかない情報を生成する現象で、2024年の研究ではSelfCheckGPT、FActScore、TruthfulQAなどの検出技術が進化し、医療・法務・金融分野では致命的な影響を与える可能性があります。

- **バイアス**：学習データの偏りによる差別的な出力で、2024年のOpenEthics研究では29のオープンソースLLMで包括的な倫理評価を実施し、性別・人種・年齢・地域などの属性に対する不公平な判断のリスクが確認されています。

- **プロンプトインジェクション攻撃**：悪意のある指示によってAIの動作を意図的に操作する攻撃で、2024年の日本AI Safety Instituteの報告では敵対的プロンプトへの対策が重要課題として位置づけられ、システムの制御を奪われ機密情報の漏洩や不正な操作のリスクがあります。

**他の選択肢が不適切な理由：**

- **A**：技術的な問題ではあるが、社会的影響は限定的です。

- **C**：運用上の課題であり、安全性に直接関わるリスクではありません。

- **D**：ユーザビリティの問題であり、倫理的・安全性リスクとは異なります。 