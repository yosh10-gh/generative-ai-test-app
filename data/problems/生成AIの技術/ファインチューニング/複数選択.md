# ファインチューニング - 複数選択問題

## 問題
**Parameter-Efficient Fine-Tuning（PEFT）**の効率化手法として、現在実用化されているものを**すべて**選んでください。（複数選択）

## 選択肢
A. LoRA（Low-Rank Adaptation）

B. QLoRA（Quantized Low-Rank Adaptation）

C. Gradient Checkpointing（勾配チェックポイント）

D. DeepSpeed ZeRO（Zero Redundancy Optimizer）

E. PiSSA（Principal Singular Values and Singular Vectors Adaptation）
F. DoRA（Weight-Decomposed Low-Rank Adaptation）

## 正解
**A、B、C、D、E、F（すべて）**

## 解説
Parameter-Efficient Fine-Tuning（PEFT）は、「大きなAIモデルを効率的に学習させる技術」の総称です。これらの手法を使うことで、少ないメモリと計算量で高性能なAIモデルを作ることができます。

### **A. LoRA（Low-Rank Adaptation）**
**基本的な仕組み**：
- 大きな重み行列を2つの小さな行列の掛け算で近似
- **例**：4096×4096の大きな行列 → 4096×16と16×4096の小さな行列2つ
- **効果**：メモリ使用量を99%以上削減

**分かりやすい例**：
- 従来：辞書全体を覚え直す
- LoRA：付箋で必要な部分だけ修正

### **B. QLoRA（Quantized Low-Rank Adaptation）**
**基本的な仕組み**：
- LoRAに「量子化」という圧縮技術を組み合わせ
- データを4bitに圧縮（通常は16bit）
- **効果**：さらにメモリを75%削減

**分かりやすい例**：
- 従来：フルHD画像で保存
- QLoRA：圧縮画像で保存（でも品質はほぼ同じ）

### **C. Gradient Checkpointing（勾配チェックポイント）**
**基本的な仕組み**：
- 学習中の中間計算結果を一時的に削除
- 必要な時だけ再計算
- **効果**：メモリ使用量を50-70%削減

**分かりやすい例**：
- 従来：計算過程をすべてメモに残す
- Gradient Checkpointing：重要な部分だけメモして、あとは必要な時に再計算

### **D. DeepSpeed ZeRO（Zero Redundancy Optimizer）**
**基本的な仕組み**：
- 複数のGPUでモデルを分割して処理
- 各GPUが異なる部分を担当
- **効果**：GPU数に比例してメモリ効率が向上

**分かりやすい例**：
- 従来：1人で大きな本を全部覚える
- DeepSpeed ZeRO：チームで本を分担して覚える

### **E. PiSSA（Principal Singular Values and Singular Vectors Adaptation）**
**基本的な仕組み**：
- LoRAの改良版
- より賢い初期設定で学習を開始
- **効果**：LoRAより3-8%性能向上、学習も30-50%高速化

**分かりやすい例**：
- 従来のLoRA：ランダムな場所から学習開始
- PiSSA：最適な場所を見つけてから学習開始

### **F. DoRA（Weight-Decomposed Low-Rank Adaptation）**
**基本的な仕組み**：
- 重みを「方向」と「大きさ」に分けて学習
- LoRAより少ないパラメータで高い性能
- **効果**：LoRAより効率的で安定

**分かりやすい例**：
- 従来のLoRA：ベクトル全体を調整
- DoRA：方向と長さを別々に調整（より精密）

### **これらの技術の組み合わせ効果**

**単独使用の場合**：
- LoRA：メモリ90%削減
- QLoRA：メモリ95%削減
- Gradient Checkpointing：メモリ50-70%削減

**組み合わせ使用の場合**：
- QLoRA + Gradient Checkpointing：メモリ97%以上削減
- 全技術統合：メモリ効率99%向上

### **実際の効果**

**具体例**：
- **従来**：GPT-3（1750億パラメータ）の学習に350GB必要
- **PEFT技術使用**：同じモデルを24GBで学習可能
- **結果**：高価なサーバーではなく、普通のGPUで大型モデルを扱える

### **なぜすべて正解なのか？**

これらの技術は**すべて現在実用化されており**、多くのAI開発で実際に使われています：

- **研究機関**：大学や研究所で広く採用
- **企業**：Google、Meta、OpenAIなどが活用
- **個人開発者**：オープンソースライブラリで利用可能

### **まとめ**
これらのPEFT技術により、「大型AIモデルの民主化」が実現されています。以前は大企業や研究機関でしか扱えなかった大規模モデルを、個人や中小企業でも活用できるようになりました。

すべての選択肢が正解である理由は、これらがすべて**実用化済み**で、**組み合わせて使用可能**で、**大幅な効率化を実現**しているからです。 