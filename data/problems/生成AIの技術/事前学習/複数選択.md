# 事前学習 - 複数選択問題

## 問題
現代の大規模言語モデルの**事前学習**において採用されている主要な手法・戦略として正しいものをすべて選択してください。

## 選択肢
A. 自己回帰言語モデリング（Autoregressive Language Modeling）による次トークン予測

B. マスク言語モデリング（Masked Language Modeling）による双方向文脈学習  

C. 対照学習（Contrastive Learning）による表現獲得

D. 段階的学習（Curriculum Learning）による効率的データ活用

## 正解
**A、B、C、D（すべて正解）**

## 解説
現代の大規模言語モデルの事前学習では、複数の学習手法が組み合わせて使用されており、すべての選択肢が実際に採用されている主要な手法です。

### **A. 自己回帰言語モデリング（Autoregressive LM）**

**技術的原理**：
```
P(x₁, x₂, ..., xₙ) = ∏ᵢ₌₁ⁿ P(xᵢ|x₁, ..., xᵢ₋₁)
```

**代表的なモデル**：
- **GPT系列**（GPT-1/2/3/4）：左から右への因果的予測
- **PaLM (540B)**：Google の大規模自己回帰モデル
- **LLaMA系列**：Meta の効率的自己回帰モデル

**訓練目標**：
```
L = -∑ᵢ log P(xᵢ|x₁,...,xᵢ₋₁; θ)
```

**利点**：
- **生成能力**：自然な文章生成
- **因果性保持**：時系列依存関係の学習
- **実装の単純性**：Decoder-only アーキテクチャ

### **B. マスク言語モデリング（Masked LM）**

**技術的原理**：
- 入力の15%をランダムにマスク
- [MASK]、元トークン、ランダムトークンの確率配分

**代表的なモデル**：
- **BERT系列**：双方向Encoder による文脈理解
- **RoBERTa**：最適化されたBERT訓練手法
- **ELECTRA**：置換検出による効率化

**訓練目標**：
```
L = -∑ᵢ∈M log P(xᵢ|x₁,...,x̃ᵢ,...,xₙ; θ)
```
（M: マスク位置集合）

**利点**：
- **双方向文脈**：左右両方向の情報活用
- **理解タスク特化**：分類、QA、NLI等
- **表現学習**：豊富な文脈表現

### **C. 対照学習（Contrastive Learning）**

**技術的原理**：
- 正例ペア：類似表現を近づける
- 負例ペア：異なる表現を遠ざける

**InfoNCE損失**：
```
L = -log(exp(sim(z₊,z)/τ) / ∑ⱼexp(sim(zⱼ,z)/τ))
```

**代表的手法**：
- **SimCLR**：視覚表現学習
- **CLIP**：視覚-言語対照学習  
- **SimCSE**：文表現の対照学習
- **E5**：テキスト埋め込みの対照学習

**2024年の発展**：
- **Multimodal Contrastive Learning**
- **Hard Negative Mining**
- **温度調整戦略**の最適化

### **D. 段階的学習（Curriculum Learning）**

**技術的原理**：
- **簡単→困難**な順序でデータを提示
- 学習効率と安定性の向上

**実装戦略**：
**1. データ難易度ベース**：
- 文長：短文→長文
- 語彙：高頻度→低頻度語
- 構文：単純→複雑構造

**2. タスク難易度ベース**：
- Next Sentence Prediction → Complex Reasoning
- Factual QA → Multi-step Reasoning

**3. ドメイン難易度ベース**：
- Common Crawl → Scientific Papers
- News → Creative Writing

**最新の研究成果**：
- **Chinchilla**：最適なデータ順序戦略
- **PaLM**：数学的推論の段階的学習
- **Code Llama**：プログラミング能力の段階的獲得

### **統合的アプローチ（2024年動向）**

**Multi-Task Pre-training**：
```python
# 疑似コード例
loss_total = λ₁*L_autoregressive + λ₂*L_masked + λ₃*L_contrastive
```

**段階的複合学習**：
1. **Phase 1**: 基本的言語モデリング（A, B）
2. **Phase 2**: 対照学習による表現精緻化（C）
3. **Phase 3**: 段階的難易度調整（D）

**実例：最新モデルでの統合**：
- **GPT-4**: 自己回帰 + 強化学習 + 段階的学習
- **Claude**: Constitutional AI + 対照学習
- **Gemini**: マルチモーダル対照学習 + 段階的学習

### **実装時の考慮事項**

**計算効率**：
- **Mixed Precision Training**：FP16/BF16
- **Gradient Accumulation**：メモリ制約下での大バッチ学習
- **Data Parallel / Model Parallel**：分散学習

**学習安定化**：
- **Learning Rate Scheduling**：Warmup + Cosine Decay
- **Gradient Clipping**：勾配爆発防止
- **Layer Normalization**：Pre-LN vs Post-LN

これら4つの手法は相互補完的で、組み合わせることで最高性能を実現します。 