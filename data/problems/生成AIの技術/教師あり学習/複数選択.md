## 複数選択
### 教師あり学習
教師あり学習のアルゴリズムとして正しいものを全て選びなさい。

A. ランダムフォレスト（Random Forest）
B. k-means法（k-means Clustering）
C. サポートベクターマシン（Support Vector Machine）
D. 線形回帰（Linear Regression）

答え：A、C、D

解説：
選択肢A：ランダムフォレスト（Random Forest）は正解です。決定木を基本学習器とする代表的なアンサンブル学習手法で、分類・回帰両方に使用できる教師あり学習アルゴリズムです。複数の決定木をランダムに構築し、それらの予測結果を多数決（分類）や平均値（回帰）で統合します。バギング（Bootstrap Aggregating）とランダム特徴選択を組み合わせることで、個々の決定木の過学習を抑制し、高い汎化性能を実現します。特徴量の重要度も算出でき、解釈性に優れています。

選択肢B：k-means法（k-means Clustering）は誤りです。これは教師なし学習（Unsupervised Learning）のクラスタリング手法です。ラベル情報を使わずに、データをk個のクラスタに分割します。各データポイントを最も近いクラスタ中心に割り当て、クラスタ中心を更新する処理を収束まで繰り返します。目的変数（正解ラベル）が存在しないため、教師あり学習には分類されません。

選択肢C：サポートベクターマシン（Support Vector Machine, SVM）は正解です。高次元空間での線形分離や、カーネル法を用いた非線形分離が可能な強力な教師あり学習アルゴリズムです。訓練データの中で決定境界に最も近いサポートベクターのマージンを最大化することで汎化性能を向上させます。分類問題だけでなく、SVR（Support Vector Regression）として回帰問題にも適用可能です。

選択肢D：線形回帰（Linear Regression）は正解です。最も基本的な回帰手法の一つで、説明変数と目的変数の間の線形関係をモデル化します。最小二乗法によりパラメータを推定し、y = β₀ + β₁x₁ + β₂x₂ + ... + βₙxₙの形で表現されます。統計的解釈が容易で、特徴量の影響度を回帰係数から直接読み取れます。Ridge回帰やLasso回帰などの正則化手法も広く使用されています。 