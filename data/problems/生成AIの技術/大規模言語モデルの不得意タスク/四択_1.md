## 問題
### 大規模言語モデルの不得意タスク
大規模言語モデル（LLM）が特に不得意とするタスクの特徴として、最も適切な説明はどれですか？

A. 自然言語の文法的な解析や構文理解

B. 正確な数値計算や論理的推論を要する問題

C. 大量のテキストデータからの情報抽出

D. 多言語間での翻訳や言語変換

## 正解B

解説：
大規模言語モデルは、正確な数値計算や厳密な論理的推論を要するタスクを特に不得意とします。これは、LLMが統計的なパターン学習に基づいて動作するため、数学的な正確性や論理的な一貫性を保証することが困難だからです。

**最新研究による裏付け**：
・2025年の「Investigating Symbolic Capabilities of Large Language Models」研究では、記号的計算タスク（加算、乗算、剰余演算など）において、記号の数が増加するにつれてLLMの性能が大幅に低下することが実証されています
・「Logic Haystacks」研究では、長文コンテキストでの論理推論において、わずか128節程度で推論能力が著しく低下することが示されています
・複雑な算数問題や多段階の論理推論では、中間ステップでの誤りが累積しやすく、最終的な答えが間違ってしまうことが体系的に確認されています

**技術的背景**：
・次トークン予測の学習目標が、厳密な論理的関係性の理解に適していない
・統計的パターン学習では、数学的正確性や論理的一貫性を保証できない
・記号的推論における汎化能力の限界

Chain-of-Thought（CoT）プロンプティングやThinking Modelsなどの手法により改善は見られますが、根本的な限界は残っています。一方、文法解析（A）、情報抽出（C）、翻訳（D）は、LLMが比較的得意とする言語処理タスクです。 