## 問題
### トランスフォーマー
Transformer と従来の RNN/LSTM と比較した場合の主要な優位性として最も適切でないものはどれか。

A. 並列処理による学習・推論の高速化

B. 長距離依存関係の効率的な捕捉

C. メモリ使用量の大幅な削減

D. 勾配消失問題の軽減

## 正解C

解説：
選択肢Cの「メモリ使用量の大幅な削減」は、Transformerの優位性ではありません。実際には、Transformerは自己注意機構でシーケンス長の二乗に比例するメモリを消費するため、長いシーケンスではRNN/LSTMよりもメモリ使用量が多くなる場合があります。一方、選択肢AのTransformerは並列処理が可能で、RNN/LSTMの逐次処理と比べて大幅な高速化を実現します。選択肢Bでは、自己注意機構により任意の位置間の直接的な接続が可能で、RNN/LSTMが苦手とする長距離依存関係を効率的に学習できます。選択肢Dでは、残差接続（Residual Connection）とLayer Normalizationにより、深いネットワークでも勾配が安定して伝播し、RNN/LSTMで問題となる勾配消失を軽減します。これらの技術革新により、TransformerはGPT、BERT等の基盤となり、自然言語処理分野を革新しました。 