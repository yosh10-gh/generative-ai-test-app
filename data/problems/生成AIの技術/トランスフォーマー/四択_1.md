## 四択_①
### トランスフォーマー
Transformer アーキテクチャの最も重要な革新的特徴はどれか。

A. 畳み込みニューラルネットワーク（CNN）による画像認識の高速化
B. 自己注意機構（Self-Attention）による並列処理とグローバル依存関係の捕捉
C. 再帰的ニューラルネットワーク（RNN）による逐次処理の効率化
D. 決定木アルゴリズムによる解釈可能な分類処理

答え：B

解説：
Transformerの最大の革新は、選択肢Bの自己注意機構（Self-Attention）です。この仕組みにより、シーケンス内の任意の位置間の依存関係を一度に計算でき、従来のRNNやLSTMのような逐次処理の制約を排除しました。自己注意機構は、入力シーケンスの各要素が他のすべての要素とどの程度関連しているかを動的に計算し、重要度に応じて重み付けを行います。これにより、長距離依存関係の捕捉が可能になり、並列処理による大幅な学習・推論の高速化を実現しました。選択肢AのCNNは主に画像処理用、選択肢CのRNNは逐次処理で並列化が困難、選択肢Dの決定木は深層学習ではありません。Transformerは2017年の「Attention is All You Need」論文で発表され、現代の大規模言語モデルの基盤技術となっています。 